
# 使用redis可能遇到的问题

### 缓存雪崩和缓存穿透、缓存击穿解决方案
   - 缓存雪崩
        - 缓存雪崩是指在我们设置缓存时采用了相同的过期时间，导致缓存在某一时刻同时失效，请求全部转发到DB，DB瞬时压力过重雪崩。
        或者某个时刻缓存服务器瞬间宕机（最严重）。
        （缓存同一时间大面积的失效，所以，后面的请求都会落到数据库上，造成数据库短时间内承受大量请求而崩掉。）
        - 解决方案
            - 同时失效的话，过期时间加一个随机值。分散缓存过期时间，防止集体失效。
            - 如果是缓存服务器宕机，
                1. 发生前：尽量保证整个redis集群的高可用性。哨兵模式，发现机器宕机尽快补上。选择合适的内存淘汰策略。
                2. 发生中：本地ehcache缓存+hystrix限流&降级。避免数据库崩掉
                3. 发生后：利用redis持久化机制保存数据尽快恢复缓存。
   - 缓存击穿
        -   对于一些设置了过期时间的key，如果这些key可能会在某些时间点被超高并发地访问，是一种非常“热点”的数据。
        这个时候，需要考虑一个问题：缓存被“击穿”的问题，这个和缓存雪崩的区别在于这里针对某一key缓存，前者则是很多key。
        - 解决方案：
            1. 使用互斥锁(mutex key) （没必要）
            业界比较常用的做法，是使用mutex。简单地来说，就是在缓存失效的时候（判断拿出来的值为空），不是立即去load db，而是先使用缓存工具的某些带成功操作返回值的操作（比如Redis的SETNX或者Memcache的ADD）去set一个mutex key，当操作返回成功时，再进行load db的操作并回设缓存；否则，就重试整个get缓存的方法。
            2. "提前"使用互斥锁(mutex key)：
            在value内部设置1个超时值(timeout1), timeout1比实际的memcache timeout(timeout2)小。当从cache读取到timeout1发现它已经过期时候，马上延长timeout1并重新设置到cache。然后再从数据库加载数据并设置到cache中。
            3. "永远不过期"：
                   (1) 从redis上看，确实没有设置过期时间，这就保证了，不会出现热点key过期问题，也就是“物理”不过期。
                   (2) 从功能上看，如果不过期，那不就成静态的了吗？所以我们把过期时间存在key对应的value里，如果发现要过期了，通过一个后台的异步线程进行缓存的构建，也就是“逻辑”过期
            4. 资源保护：
                - 采用netflix的hystrix，可以做资源的隔离保护主线程池。
    
   - 缓存穿透
        - 缓存穿透是指查询一定不存在的数据，导致所有的请求都落到数据库上，造成数据库短时间内承受大量请求而崩。
        - 解决办法： 
        有很多种方法可以有效地解决缓存穿透问题，最常见的则是采用布隆过滤器，将所有可能存在的数据哈希到一个足够大的bitmap中，一个一定不存在的数据会被 这个bitmap拦截掉，从而避免了对底层存储系统的查询压力。
        另外也有一个更为简单粗暴的方法（我们采用的就是这种），如果一个查询返回的数据为空（不管是数 据不存在，还是系统故障），我们仍然把这个空结果进行缓存，但它的过期时间会很短，最长不超过五分钟。   
    
### 如何解决Redis的并发竞争Key问题，了解 redis 事务的 CAS 方案吗？

   - 所谓 Redis 的并发竞争 Key 的问题也就是多个系统同时对一个 key 进行操作，但是最后执行的顺序和我们期望的顺序不同，这样也就导致了结果的不同！而且 redis 自己就有天然解决这个问题的 CAS 类的乐观锁方案。
   - 解决：加锁！分布式锁（zookeeper（可靠） 和 redis 都可以实现分布式锁）。
           

### 如何保证缓存与数据库双写时的数据一致性。TODO
   - 一般来说，如果允许缓存可以稍微的跟数据库偶尔有不一致的情况，也就是说如果你的系统不是严格要求 “缓存+数据库” 必须保持一致性的话，最好不要做这个方案，即：读请求和写请求串行化，串到一个内存队列里去。
   串行化可以保证一定不会出现不一致的情况，但是它也会导致系统的吞吐量大幅度降低，用比正常情况下多几倍的机器去支撑线上的一个请求。
   - Cache Aside Pattern
    - 最经典的缓存+数据库读写的模式，就是 Cache Aside Pattern
        - 读的时候，先读缓存，缓存没有的话，就读数据库，然后取出数据后放入缓存，同时返回响应。
        - 更新的时候，先更新数据库，然后再删除缓存。
    - 为什么是先删除缓存，而不是更新缓存？
        1. 复杂缓存，缓存不单单是数据库直接取出，可能需要其他表数据运算。
        2. 更新缓存代价比较高。如果涉及多表，其他表数据缓存也得更新
        3. 该缓存数据是否是一个热点数据？不是的话，没必要频繁更新缓存。类似lazy计算。
   
   - 最初级的缓存不一致问题解决方案
   
        - 先更新数据库，再删除缓存。如果删除缓存失败了，那么会导致数据库中是新数据，缓存中是旧数据，数据就出现了不一致。
        - 解决思路：先删除缓存，再更新数据库。如果数据库更新失败了，那么数据库中是旧数据，缓存中是空的，那么数据不会不一致。因为读的时候缓存没有，所以去读了数据库中的旧数据，然后更新到缓存中。
        
   - 比较复杂的数据不一致问题。
        - 数据发生了变更，先删除了缓存，然后要去修改数据库，此时还没修改。一个请求过来，去读缓存，发现缓存空了，去查询数据库，查到了修改前的旧数据，放到了缓存中。随后数据变更的程序完成了数据库的修改。数据库和缓存中的数据不一样了...
        - 在高并发情况会出现这种问题。解决方案：[链接](https://github.com/doocs/advanced-java/blob/master/docs/high-concurrency/redis-consistence.md)
            - 更新数据的时候，根据数据的唯一标识，将操作路由之后，发送到一个 jvm 内部队列中。读取数据的时候，如果发现数据不在缓存中，那么将重新读取数据+更新缓存的操作，根据唯一标识路由之后，也发送同一个 jvm 内部队列中。
              
              一个队列对应一个工作线程，每个工作线程串行拿到对应的操作，然后一条一条的执行。这样的话，一个数据变更的操作，先删除缓存，然后再去更新数据库，但是还没完成更新。此时如果一个读请求过来，没有读到缓存，那么可以先将缓存更新的请求发送到队列中，此时会在队列中积压，然后同步等待缓存更新完成。
              
              这里有一个优化点，一个队列中，其实多个更新缓存请求串在一起是没意义的，因此可以做过滤，如果发现队列中已经有一个更新缓存的请求了，那么就不用再放个更新请求操作进去了，直接等待前面的更新操作请求完成即可。
              
              待那个队列对应的工作线程完成了上一个操作的数据库的修改之后，才会去执行下一个操作，也就是缓存更新的操作，此时会从数据库中读取最新的值，然后写入缓存中。
              
              如果请求还在等待时间范围内，不断轮询发现可以取到值了，那么就直接返回；如果请求等待的时间超过一定时长，那么这一次直接从数据库中读取当前的旧值。。。